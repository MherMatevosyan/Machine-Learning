{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    \"\"\"\n",
    "    DecisionTree class, that represents one Decision Tree\n",
    "\n",
    "    :param max_tree_depth: maximum depth for this tree.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_tree_depth):\n",
    "\n",
    "        # if not trained return 0.5 probability\n",
    "        self.tree = [{'proba': 0.5,\n",
    "                      'node': 'is_terminal',\n",
    "                      'index': 0}]\n",
    "        self.max_depth = max_tree_depth\n",
    "\n",
    "    def dict_of_values(self, data):\n",
    "        \n",
    "        \"\"\"\n",
    "        :param results: dictionary\n",
    "        :param data: np.array      \n",
    "        \"\"\"\n",
    "        l1 = len(np.array([data[x] for x in range(len(data)) if data[x][0] == 1]))\n",
    "        l2 = len(np.array([data[x] for x in range(len(data)) if data[x][0] == 0]))        \n",
    "        return {'1':l1,'0':l2}\n",
    "        \n",
    "    def gini_impurity(self,data1, data2):\n",
    "        \"\"\"\n",
    "        :param data1: 2 dimensional python list or numpy 2 dimensional array\n",
    "        :param data2: 2 dimensional python list or numpy 2 dimensional array\n",
    "        :return: float\n",
    "        \"\"\"\n",
    "        data_length = len(data1)+len(data2)\n",
    "        one_fraction = len(data1)/data_length\n",
    "        two_fraction = len(data2)/data_length\n",
    "        Gini = float(one_fraction*(1-one_fraction)+two_fraction*(1-two_fraction))\n",
    "        return Gini\n",
    "\n",
    "    def divide_data(self, data, feature_column, feature_val):\n",
    "        \"\"\"\n",
    "        :param data: 2 dimensional python list or numpy 2 dimensional array\n",
    "        :param feature_column: index ov the column to split the data\n",
    "        :param feature_val: value of the feature\n",
    "        :return: data1, data2: 2 2 dimensinal python lists or 2 numpy 2 dimensional arrays\n",
    "        \"\"\"\n",
    "        data1 = [x for x in data if x[feature_column] < feature_val]\n",
    "        data2 = [x for x in data if x[feature_column] >= feature_val]\n",
    "        return data1, data2\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        :param X: 2 dimensional python list or numpy 2 dimensional array\n",
    "        :param Y: 1 dimensional python list or numpy 1 dimensional array\n",
    "        \"\"\"\n",
    "        self.tree = []\n",
    "\n",
    "        # merge labels and data and put them in a list to iterate over\n",
    "        my_data = list([np.concatenate((Y,X),axis = 1)])\n",
    "\n",
    "        # depth of the tree\n",
    "        depth = 0\n",
    "\n",
    "        # index for each child node\n",
    "        index = 0\n",
    "\n",
    "        # incr to keep track of left and right nodes\n",
    "        my_subtrees = []\n",
    "        increment = -1\n",
    "\n",
    "        my_tree = []\n",
    "        while depth < self.max_depth+1:\n",
    "\n",
    "            # temporary list to keep all nodes of the tree on current depth\n",
    "            my_data_test = []\n",
    "\n",
    "            # First iteration iterates only on entire data\n",
    "            # each next iteration iterates over all nodes on current depth\n",
    "            for data in my_data:\n",
    "\n",
    "                # calculate Gini impurity for parent node\n",
    "                d1 = np.array([data[x] for x in range(len(data)) if data[x][0] == 1])\n",
    "                d2 = np.array([data[x] for x in range(len(data)) if data[x][0] == 0])\n",
    "                Gp = self.gini_impurity(d1,d2)\n",
    "\n",
    "                # check if parent node is a terminal node  and jump to next iteration\n",
    "                # node is terminal when Gini impurity is 0 or max_depth is reached\n",
    "                if Gp == 0 or depth == self.max_depth:\n",
    "                    proba = len(d1)/len(data)\n",
    "                    \n",
    "                    # add a terminal node to the tree\n",
    "                    self.tree.append({'proba': proba,\n",
    "                                    'node': 'is_terminal',\n",
    "                                    'index': len(self.tree)})\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # count of features\n",
    "                feature_len = len(data[0])-1    # first column of data is label column\n",
    "\n",
    "                # list of best Gini impurities for each feature\n",
    "                Ginis = []\n",
    "\n",
    "                # iterate over features to find best feature to split the data over\n",
    "                for feature in range(1,feature_len+1):\n",
    "\n",
    "                    # list of all Gini impurities for current feature\n",
    "                    feature_Gini = []\n",
    "\n",
    "                    # list of unique feature values by ascending order\n",
    "                    sorted_features = sorted(list(set([x[feature] for x in data])))\n",
    "\n",
    "                    # if there is only one value of feature skip splitting\n",
    "                    if len(sorted_features) <= 1:\n",
    "                        continue\n",
    "\n",
    "                    # mid points for each neighbouring feature values\n",
    "                    mid_points = [(sorted_features[i]+sorted_features[i+1])/2 for i in range(len(sorted_features)-1)]\n",
    "\n",
    "                    # iterating over each mid point to find best division for current feature\n",
    "                    for point in mid_points:\n",
    "\n",
    "                        # divide data into 2 parts with point\n",
    "                        child1,child2 = self.divide_data(data,feature,point)\n",
    "\n",
    "                        # calculate Gini of first child\n",
    "                        c1d1 = np.array([child1[x] for x in range(len(child1)) if child1[x][0] == 1])\n",
    "                        c1d2 = np.array([child1[x] for x in range(len(child1)) if child1[x][0] == 0])\n",
    "                        Gc1 = self.gini_impurity(c1d1,c1d2)\n",
    "\n",
    "                        # calculate Gini of second child\n",
    "                        c2d1 = np.array([child2[x] for x in range(len(child2)) if child2[x][0] == 1])\n",
    "                        c2d2 = np.array([child2[x] for x in range(len(child2)) if child2[x][0] == 0])\n",
    "                        Gc2 = self.gini_impurity(c2d1,c2d2)\n",
    "\n",
    "                        # calculate information gain\n",
    "                        IG = Gp-len(child1)/len(data)*Gc1-len(child2)/len(data)*Gc2\n",
    "\n",
    "                        # append IG and division point and index of feature for current feature\n",
    "                        feature_Gini.append([IG,point,feature])\n",
    "\n",
    "                    # after iterating on all mid points find the best division point by IG\n",
    "                    # append max IG to overall Ginis for current feature\n",
    "                    Ginis.append(max(feature_Gini))\n",
    "\n",
    "                # after iterating over all features find best division point for current node    \n",
    "                # best division point by IG\n",
    "                best_point = max(Ginis)\n",
    "\n",
    "                # add probability of being from class 1.0\n",
    "                proba = len(np.array([data[x] for x in range(len(data)) if data[x][0] == 1]))/len(data)\n",
    "                \n",
    "                # create a node\n",
    "                node = {'feature': best_point[2]-1,\n",
    "                        'value': best_point[1],\n",
    "                        'proba': proba,\n",
    "                        'node': 'is_not_terminal',\n",
    "                        'index': len(self.tree),\n",
    "                        'ltree': index+1,\n",
    "                        'rtree': index+2}\n",
    "                index += 2\n",
    "                # add the node to the tree\n",
    "                self.tree.append(node)\n",
    "\n",
    "                # divide for the best point\n",
    "                best_div = self.divide_data(data,best_point[2],best_point[1])\n",
    "\n",
    "                # append childs \n",
    "                my_data_test.append(best_div[0])\n",
    "                my_subtrees.append('ltree')\n",
    "                my_data_test.append(best_div[1])\n",
    "                my_subtrees.append('rtree')\n",
    "                increment += 1\n",
    "\n",
    "            # move to next iteration going to the next depth nodes of the tree   \n",
    "            # pass all childs to my_data to iterate over them on next iteration and increase depth\n",
    "            my_data = my_data_test\n",
    "            depth += 1\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        :param X: 2 dimensional python list or numpy 2 dimensional array\n",
    "        :return: Y: 1 dimension python list with labels\n",
    "        \"\"\"\n",
    "        # initialize array to store the scores\n",
    "        result = np.array([])\n",
    "        for data_point in X:\n",
    "            k = 0\n",
    "            while True:\n",
    "                # start from first node if it is a terminal node return probability\n",
    "                if self.tree[k]['node'] == 'is_terminal':\n",
    "                    proba = self.tree[k]['proba']\n",
    "                    result = np.append(result,proba)\n",
    "                    break\n",
    "                else:\n",
    "                    # check if the input goes to left subtree or right subtree\n",
    "                    # update k to be the subtree the input goes into\n",
    "                    if data_point[self.tree[k]['feature']] < self.tree[k]['value']:\n",
    "                        k = self.tree[k]['ltree']\n",
    "                    else:\n",
    "                        k = self.tree[k]['rtree']\n",
    "                # repeat the procces until a terminal node is reached\n",
    "\n",
    "        return result.reshape(X.shape[0],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandomForest(object):\n",
    "    \"\"\"\n",
    "    RandomForest a class, that represents Random Forests.\n",
    "\n",
    "    :param num_trees: Number of trees in the random forest\n",
    "    :param max_tree_depth: maximum depth for each of the trees in the forest.\n",
    "    :param ratio_per_tree: ratio of points to use to train each of\n",
    "        the trees.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_trees, max_tree_depth, ratio_per_tree=0.5):\n",
    "        self.num_trees = num_trees\n",
    "        self.max_tree_depth = max_tree_depth\n",
    "        self.ratio_per_tree = ratio_per_tree\n",
    "        self.trees = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        :param X: 2 dimensional python list or numpy 2 dimensional array\n",
    "        :param Y: 1 dimensional python list or numpy 1 dimensional array\n",
    "        \"\"\"\n",
    "        self.trees = []\n",
    "        \n",
    "        for t in tqdm(range(self.num_trees)):\n",
    "            \n",
    "            # initialize a decision tree\n",
    "            clf = DecisionTree(self.max_tree_depth)\n",
    "            \n",
    "            # randomly shuffle the data\n",
    "            idx = np.random.randint(len(X), size=int(len(X)*self.ratio_per_tree))\n",
    "            Xr = X[idx,:]\n",
    "            Yr = Y[idx,:]\n",
    "            \n",
    "            # fit a decision tree\n",
    "            clf.fit(Xr,Yr)\n",
    "            \n",
    "            # append each tree to tree list\n",
    "            self.trees.append(clf)\n",
    "\n",
    "        return self.trees\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        :param X: 2 dimensional python list or numpy 2 dimensional array\n",
    "        :return: (Y, conf), tuple with Y being 1 dimension python\n",
    "        list with labels, and conf being 1 dimensional list with\n",
    "        confidences for each of the labels.\n",
    "        \"\"\"\n",
    "        Y = []\n",
    "        conf = []\n",
    "        \n",
    "        for x in X:\n",
    "            \n",
    "            # make votes for each data point in X\n",
    "            voting = [1 if t.predict(np.array([x]))>=0.5 else 0 for t in self.trees ]\n",
    "            \n",
    "            # find class with most votes\n",
    "            y = max(set(voting), key=voting.count)\n",
    "            Y.append(y)\n",
    "            \n",
    "            # find the confidence of votes, i.e. what proportion of trees voted for the winning class\n",
    "            c = voting.count(y)/len(self.trees)\n",
    "            conf.append(c)\n",
    "            \n",
    "        return (np.array(Y).reshape(len(Y),1), np.array(conf).reshape(len(Y),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy_score(Y_true, Y_predict):\n",
    "    \"\"\"\n",
    "    Calculates what portion of the data had the correct label predicted.\n",
    "    :param Y_true: list or numpy array of true labels\n",
    "    :param Y_predict: list or numpy array of predicted labels\n",
    "    \"\"\"\n",
    "    try:\n",
    "        acc = dict(zip(*np.unique((Y_true == Y_predict), return_counts=True)))[True]/len(Y_true)\n",
    "    # in case there is no True label\n",
    "    except:\n",
    "        acc = 0\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "filename = 'SPECTF.dat'\n",
    "data = np.loadtxt(filename, delimiter=',')\n",
    "X = data[:, 1:]\n",
    "y = np.array([data[:, 0]]).T\n",
    "n, d = X.shape\n",
    "\n",
    "# Shuffle data\n",
    "c = list(zip(X, y))\n",
    "random.shuffle(c)\n",
    "Xt, yt = zip(*c)\n",
    "X = np.array(Xt)\n",
    "y = np.array(yt)\n",
    "\n",
    "# Define train and test sets\n",
    "train_size  = int(0.75*len(X))\n",
    "Xtrain = X[1:train_size, :]  # train on 75% of data\n",
    "Xtest = X[train_size:, :]\n",
    "ytrain = y[1:train_size, :]  # test on 25% of data\n",
    "ytest = y[train_size:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting Dt\n",
      "train accuracy Dt:  0.8391959798994975\n",
      "test accuracy Dt:  0.6268656716417911 \n",
      "\n",
      "fitting Rf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:17<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy Rf:  0.9195979899497487\n",
      "test accuracy Rf:  0.7761194029850746 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train Decision Tree\n",
    "print('fitting Dt')\n",
    "dt = DecisionTree(7)\n",
    "dt.fit(Xtrain, ytrain)\n",
    "\n",
    "# output predictions on the remaining data\n",
    "y_pred_dt = dt.predict(Xtest)\n",
    "accuracy_dt = accuracy_score(ytest, y_pred_dt)\n",
    "print('train accuracy Dt: ', accuracy_score(ytrain, dt.predict(Xtrain)))\n",
    "print('test accuracy Dt: ', accuracy_dt,'\\n')\n",
    "\n",
    "# train on Random Forest\n",
    "print('fitting Rf')\n",
    "rf = RandomForest(25, 7)\n",
    "forest = rf.fit(Xtrain, ytrain)\n",
    "\n",
    "# output predictions on the remaining data\n",
    "y_pred_rf = rf.predict(Xtest)\n",
    "accuracy_rf = accuracy_score(ytest, y_pred_rf[0])\n",
    "print('train accuracy Rf: ', accuracy_score(ytrain, rf.predict(Xtrain)[0]))\n",
    "print('test accuracy Rf: ', accuracy_rf,'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
